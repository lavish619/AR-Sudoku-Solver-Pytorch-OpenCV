{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "(28, 28, 1) train samples\n",
      "(28, 28, 1) test samples\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The complete code in this file was copied from the keras repository,\n",
    "from the examples directory of vision , just to train the model on the mnist dataset\n",
    "and get the trained model.\n",
    "'''\n",
    "\n",
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 15 epochs\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28,1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train[0].shape, \"train samples\")\n",
    "print(x_test[0].shape, \"test samples\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "## Build the model\n",
    "\"\"\"\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.3664 - accuracy: 0.8888 - val_loss: 0.0846 - val_accuracy: 0.9762\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.1106 - accuracy: 0.9671 - val_loss: 0.0541 - val_accuracy: 0.9853\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0834 - accuracy: 0.9745 - val_loss: 0.0477 - val_accuracy: 0.9875\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0692 - accuracy: 0.9785 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0627 - accuracy: 0.9808 - val_loss: 0.0391 - val_accuracy: 0.9895\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0550 - accuracy: 0.9831 - val_loss: 0.0351 - val_accuracy: 0.9903\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0510 - accuracy: 0.9841 - val_loss: 0.0346 - val_accuracy: 0.9915\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0461 - accuracy: 0.9853 - val_loss: 0.0316 - val_accuracy: 0.9910\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0436 - accuracy: 0.9859 - val_loss: 0.0315 - val_accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.0304 - val_accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c90d774788>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.026001665741205215\n",
      "Test accuracy: 0.991100013256073\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "model.save(\"cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 0 0 0 1 0 0 0 8]\n",
      " [0 5 0 8 0 7 0 1 0]\n",
      " [0 0 4 0 9 0 7 0 0]\n",
      " [0 6 0 7 0 1 0 2 0]\n",
      " [5 0 8 0 8 0 1 0 7]\n",
      " [0 1 0 5 0 2 7 8 0]\n",
      " [0 0 7 0 4 0 8 0 0]\n",
      " [0 8 0 3 0 9 0 4 0]\n",
      " [3 0 0 0 5 0 0 0 8]]\n",
      "[[8 0 0 0 1 0 0 0 8]\n",
      " [0 5 0 8 0 7 0 1 0]\n",
      " [0 0 4 0 9 0 7 0 0]\n",
      " [0 6 0 7 0 1 0 2 0]\n",
      " [5 0 8 0 8 0 1 0 7]\n",
      " [0 1 0 5 0 2 7 8 0]\n",
      " [0 0 7 0 4 0 8 0 0]\n",
      " [0 8 0 3 0 9 0 4 0]\n",
      " [3 0 0 0 5 0 0 0 8]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from math import floor\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class Sudoku:\n",
    "    \n",
    "    def __init__(self, path ):\n",
    "            self.path = path\n",
    "\n",
    "    def show_image(self,img):\n",
    "        '''function to show an image'''\n",
    "\n",
    "        cv2.imshow(\"image\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def display_contours(self, img, contours, color = (0,255 , 0), thickness = 2 ):\n",
    "        '''function to display identified contours of sudoku board'''\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        cont_image = cv2.drawContours(img, contours, -1, color, thickness)\n",
    "        show_image(cont_image)\n",
    "\n",
    "\n",
    "    def display_corners(self, img, corners, colour=(0, 0, 255),radius=7):\n",
    "        '''function to display corners of sudoku board'''\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        for corner in corners:\n",
    "            img = cv2.circle(img, tuple(corner), radius, colour, -1)\n",
    "        show_image(img)\n",
    "\n",
    "\n",
    "    def read_process_image(self, path):\n",
    "\n",
    "        img = cv2.imread(path, 0) #0 is flag for grayscale(cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        #gaussian blurring\n",
    "        kernel_size = (9,9) #Tried other values but found (9,9)is the best kernel size.\n",
    "        img = cv2.GaussianBlur(img.copy(), kernel_size, 0)\n",
    "\n",
    "        #thresholding\n",
    "        img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "        # Now to make text and gridlines more bolder.we will do erosion so\n",
    "        # that zero(black) pixel values of text and gridlines will erode the non-zero(white)\n",
    "        #pixel values and text becomes bolder.\n",
    "        kernel = np.ones((2,2),np.uint8)\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel) #erosion followed by dilation (cv2.MORPH_OPEN)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def get_contours(self, img, show_contours):\n",
    "\n",
    "        #for contour detection, it needs object to be white present in a black background.\n",
    "        # so, first we will invert the image.\n",
    "        img = cv2.bitwise_not(img,img)\n",
    "\n",
    "        # now find contours\n",
    "        #outer contours(boundry of sudoku)\n",
    "        ext_contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        #all contours(numbers, grid lines)\n",
    "        contours, _ = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #     # Now invert the image again after finding contours\n",
    "    #     img = cv2.bitwise_not(img,img)\n",
    "\n",
    "        if show_contours:\n",
    "            display_contours(img, ext_contours)\n",
    "            display_contours(img, contours)\n",
    "\n",
    "        # we need only external contours\n",
    "        return img, ext_contours\n",
    "\n",
    "    def get_corners(self, img, contours, show_corners):\n",
    "        contours = sorted(contours, key=cv2.contourArea)# Sorting contours by area in ascending order\n",
    "        box = contours[-1]\n",
    "    ##    print(box) #printing the box will help in understanding the code written below to find corners.\n",
    "\n",
    "\n",
    "        #A function to obtain the element at 1st position of an element\n",
    "        #because 1st element will be used as a key to for finding max/min of points below.\n",
    "        def func(x):\n",
    "            return x[1]\n",
    "\n",
    "        # Bottom-right point has the largest (x + y) value\n",
    "        # Top-left has point smallest (x + y) value\n",
    "        # Bottom-left point has smallest (x - y) value\n",
    "        # Top-right point has largest (x - y) value\n",
    "        bottom_right, _ = max(enumerate([pt[0][0] + pt[0][1] for pt in box]), key=func)\n",
    "        top_left, _ = min(enumerate([pt[0][0] + pt[0][1] for pt in box]), key=func)\n",
    "        bottom_left, _ = min(enumerate([pt[0][0] - pt[0][1] for pt in box]), key=func)\n",
    "        top_right, _ = max(enumerate([pt[0][0] - pt[0][1] for pt in box]), key=func)\n",
    "\n",
    "        #x, y coordinates of 4 corner points\n",
    "        bottom_right = box[bottom_right][0]\n",
    "        top_left = box[top_left][0]\n",
    "        bottom_left = box[bottom_left][0]\n",
    "        top_right = box[top_right][0]\n",
    "\n",
    "        corners = (top_left, top_right, bottom_left, bottom_right)\n",
    "\n",
    "        if show_corners:\n",
    "            display_corners(img, corners)\n",
    "\n",
    "        return corners\n",
    "\n",
    "    def get_cropimage(self, img, corners):\n",
    "\n",
    "        top_left, top_right, bottom_left, bottom_right = corners\n",
    "\n",
    "        def distance_between(p1, p2):\n",
    "            #Gives the distance between two pixels\n",
    "            a = p2[0] - p1[0]\n",
    "            b = p2[1] - p1[1]\n",
    "            return np.sqrt((a ** 2) + (b ** 2))\n",
    "\n",
    "        input_pts = np.array([top_left+3, top_right, bottom_left, bottom_right], dtype= 'float32')\n",
    "\n",
    "        # Get the longest length in the rectangle\n",
    "        length = max([\n",
    "                distance_between(bottom_right, top_right),\n",
    "                distance_between(top_left, bottom_left),\n",
    "                distance_between(bottom_right, bottom_left),\n",
    "                distance_between(top_left, top_right)\n",
    "                ])\n",
    "\n",
    "        length = length -5 #this is done to slightly compensate for the thick outer gridline\n",
    "\n",
    "        output_pts = np.array([[0,0],[length,0],[0,length],[length,length]], dtype= 'float32')\n",
    "\n",
    "        # Gets the transformation matrix for skewing the image to\n",
    "        # fit a square by comparing the 4 before and after points\n",
    "        m = cv2.getPerspectiveTransform(input_pts, output_pts)\n",
    "\n",
    "        # Performs the transformation on the original image\n",
    "        warped = cv2.warpPerspective(img, m, (int(length), int(length)))\n",
    "    ##    warped = cv2.cvtColor(warped, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        return warped\n",
    "\n",
    "    def display_gridlines(self, img, color = (255,0,0)):\n",
    "\n",
    "        side = img.shape[0]/9\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        for i in range(9):\n",
    "            img = cv2.line(img, (floor(side*(i+1)),0),(floor(side*(i+1)),floor(side*9)), color)\n",
    "            img = cv2.line(img, (0,floor(side*(i+1))),(floor(side*9),floor(side*(i+1))), color)\n",
    "        show_image(img)\n",
    "\n",
    "    def obtain_grid(self, img, show_grid):\n",
    "        \"\"\"Infers 81 cell grid from a square image.\"\"\"\n",
    "        grid_nums = []\n",
    "        side = img.shape[0]/9\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                cell = img[floor(side*i):floor(side*(i+1)), floor(side*j):floor(side*(j+1))]\n",
    "                grid_nums.append(cell)\n",
    "\n",
    "        if show_grid:\n",
    "            display_gridlines(img)\n",
    "\n",
    "        return grid_nums\n",
    "\n",
    "    def clasify_digits(self, images):\n",
    "\n",
    "        threshold = 10\n",
    "        image_count = -1\n",
    "        labels = np.zeros((9,9), dtype = int)\n",
    "        model = load_model(\"cnn.h5\")\n",
    "\n",
    "        #show_image(images[0])\n",
    "\n",
    "        for image in images:\n",
    "            '''Initally we classify all blank cells as zeros so counting number of black pixels\n",
    "            in an image and setting a threshold value for it can help us identify it.\n",
    "\n",
    "            Then for every cell containing a number, we will use a pretrained model on mnist dataset\n",
    "            to identify the digit'''\n",
    "\n",
    "            #removing border strips of cells that might contain grid line pixel values\n",
    "            image_count = image_count + 1\n",
    "            image = image[10:-10, 10:-10]\n",
    "\n",
    "\n",
    "            flat_image = np.ndarray.flatten(image)\n",
    "\n",
    "            #count number of white pixels i.e. numbers\n",
    "            count =0\n",
    "            for pixel in flat_image:\n",
    "                if pixel!=0:\n",
    "                    count = count+1\n",
    "            #print(count,end =\" \" ) \n",
    "\n",
    "            if count< threshold:\n",
    "                #if it's a blank cell, take it as zero in the labels.\n",
    "                continue\n",
    "\n",
    "            #resize to standard mnist image input size\n",
    "\n",
    "            image = cv2.copyMakeBorder(image,5,5,5,5,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "            image = cv2.resize(image, (28,28))\n",
    "\n",
    "            #show_image(image)\n",
    "            image = np.expand_dims(image,axis=-1)\n",
    "            img = image.reshape([1]+list(image.shape))\n",
    "            #print(image.shape)\n",
    "\n",
    "            prediction = model.predict(img)\n",
    "\n",
    "            label = np.argmax(prediction, axis=-1)\n",
    "            #print(label, end = \" \")\n",
    "\n",
    "            labels[image_count//9, image_count%9] = label\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def get_sudoku(self,show_contours = False, show_corners = False, show_grid = False):\n",
    "        img = read_process_image(self.path)\n",
    "        img, ext_contours = get_contours(img, show_contours)\n",
    "        corners = get_corners(img, ext_contours, show_corners)\n",
    "        image = get_cropimage(img, corners)\n",
    "        num_imgs = obtain_grid(image, show_grid)\n",
    "\n",
    "        grid = clasify_digits(num_imgs)\n",
    "\n",
    "        return grid\n",
    "\n",
    "def isvalid(grid, row, col, num):\n",
    "    #check row\n",
    "    for i in range(9):\n",
    "        if grid[row][i]== num:\n",
    "            return False\n",
    "    #check column\n",
    "    for i in range(9):\n",
    "        if grid[i][col]== num:\n",
    "            return False\n",
    "\n",
    "    #check 3x3 block of element\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if grid[i+ (row//3)*3][j+ (col//3)*3]== num:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def solve(grid):\n",
    "    for row in range(9):\n",
    "        for col in range(9):\n",
    "            if grid[row][col] == 0:\n",
    "                #print(str(row)+str(col), end = \"  \")\n",
    "                for num in range(1,10):\n",
    "                    if isvalid(grid, row, col, num):\n",
    "                        \n",
    "                        grid[row][col]= num\n",
    "                        grid = solve(grid)\n",
    "                        grid[row][col] = 0\n",
    "                return grid\n",
    "            \n",
    "    print(grid)\n",
    "    return grid\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path1 = r'C:\\Users\\asus\\Desktop\\Sudoku-Solver\\board.png'\n",
    "sudoku = Sudoku(path1)\n",
    "grid = sudoku.get_sudoku(show_contours = False, show_corners = False, show_grid = False)\n",
    "print(grid)\n",
    "    \n",
    "\n",
    "answer = solve(grid)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gri"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
